rm( list = ls() )
setwd( "/Users/jyoung20/GitHub/TAWR2" )
input_dir <- "data/XMLAuthorCorpus"
?dir
list.files( input_dir )
files_v <- dir( path = input_dir, pattern = ".*xml" )
files_v
?regex
library( xml2 )
i <- 1
file.path( input_dir, files_v[i] )
xml_doc <- read_xml( file.path( input_dir, files_v[i] ) )
xml_doc
source( "code/corpus_functions.R" )
for( i in seq ){
# set the xml object to read
xml_doc <- read_xml( file.path( input_dir, files_v[i] ) )
# create a string of all words in the paragraphs in the document
para_text <- get_node_text( xml_doc,
xpath = "/tei:TEI/tei:text/tei:body//tei:p",
ns = c( tei = "http://www.tei-c.org/ns/1.0" )
)
# tokenize the paragraphs
word_v <- tokenize( para_text )
# relative frequency of words
freq_table <- table( word_v ) / length( word_v )
# assign it to the book_freqs_l object
book_freqs_l[[files_v[i]]] <- as.data.frame(
freq_table, stringsAsFactors = FALSE
)
}
for( i in seq_along( files_v ) ){
# set the xml object to read
xml_doc <- read_xml( file.path( input_dir, files_v[i] ) )
# create a string of all words in the paragraphs in the document
para_text <- get_node_text( xml_doc,
xpath = "/tei:TEI/tei:text/tei:body//tei:p",
ns = c( tei = "http://www.tei-c.org/ns/1.0" )
)
# tokenize the paragraphs
word_v <- tokenize( para_text )
# relative frequency of words
freq_table <- table( word_v ) / length( word_v )
# assign it to the book_freqs_l object
book_freqs_l[[files_v[i]]] <- as.data.frame(
freq_table, stringsAsFactors = FALSE
)
}
library( xml2 )
get_node_text
# setup
rm( list = ls() )
setwd( "/Users/jyoung20/GitHub/TAWR2" )
input_dir <- "data/XMLAuthorCorpus"
# use the dir function to make a vector of file names
files_v <- dir( path = input_dir, pattern = ".*xml" )
# load the xml2 library
library( xml2 )
# load the functions you need
source( "code/corpus_functions.R" )
# run the for loop to process each text
# create the object to add information to
book_freqs_l <- list()
for( i in seq_along( files_v ) ){
# set the xml object to read
xml_doc <- read_xml( file.path( input_dir, files_v[i] ) )
# create a string of all words in the paragraphs in the document
para_text <- get_node_text( xml_doc,
xpath = "/tei:TEI/tei:text/tei:body//tei:p",
ns = c( tei = "http://www.tei-c.org/ns/1.0" )
)
# tokenize the paragraphs
word_v <- tokenize( para_text )
# relative frequency of words
freq_table <- table( word_v ) / length( word_v )
# assign it to the book_freqs_l object
book_freqs_l[[files_v[i]]] <- as.data.frame(
freq_table, stringsAsFactors = FALSE
)
}
?get_node_text
# setup
rm( list = ls() )
setwd( "/Users/jyoung20/GitHub/TAWR2" )
input_dir <- "data/XMLAuthorCorpus"
files_v <- dir( path = input_dir, pattern = ".*xml" )
# load the xml2 library
library( xml2 )
# load the functions you need
source( "code/corpus_functions.R" )
help(package = "xml2")
# setup
rm( list = ls() )
setwd( "/Users/jyoung20/GitHub/TAWR2" )
input_dir <- "data/XMLAuthorCorpus"
# use the dir function to make a vector of file names
files_v <- dir( path = input_dir, pattern = ".*xml" )
# load the xml2 library
library( xml2 )
# load the functions you need
source( "code/corpus_functions.R" )
# run the for loop to process each text
# create the object to add information to
book_freqs_l <- list()
for( i in seq_along( files_v ) ){
# set the xml object to read
xml_doc <- read_xml( file.path( input_dir, files_v[i] ) )
# create a string of all words in the paragraphs in the document
para_text <- get_node_text( xml_doc,
xpath = "/tei:TEI/tei:text/tei:body//tei:p",
ns = c( tei = "http://www.tei-c.org/ns/1.0" )
)
# tokenize the paragraphs
word_v <- tokenize( para_text )
# relative frequency of words
freq_table <- table( word_v ) / length( word_v )
# assign it to the book_freqs_l object
book_freqs_l[[files_v[i]]] <- as.data.frame(
freq_table, stringsAsFactors = FALSE
)
}
class(book_freqs_l)
names(book_freqs_l)
str(book_freqs_l)
book_freqs_l
book_freqs_l[[1]]
